{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48926f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# means that my matplotlib graphs will be included in the notebook, next to the code\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import math\n",
    "import astropy\n",
    "import random\n",
    "import numpy as np\n",
    "import tables as tb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astropy.table import Table, Column, join\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "import astropy.units as u\n",
    "\n",
    "from hetdex_tools.get_spec import get_spectra\n",
    "from hetdex_api.config import HDRconfig\n",
    "from hetdex_api.detections import Detections\n",
    "from hetdex_api.elixer_widget_cls import ElixerWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b25f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure why the code below is here, it was in the Detections database and API notebook\n",
    "# https://github.com/HETDEX/hetdex_api/blob/master/notebooks/api-notebooks/03-Detections_Database_and_API.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce894e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88dea4",
   "metadata": {},
   "source": [
    "### Opens the catalogs and turns them into dataframes\n",
    "\n",
    "I like to open both catalogs separately since they are both big (HDR3 especially!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cde6112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening H20 NEP catalog and converting it into a pandas DF\n",
    "H20_NEP_catalog = fits.open('H20_NEP_VIRUS_OVERLAP_CAT_10_2021.fits', memmap = True)\n",
    "H20_NEP_data = H20_NEP_catalog[1].data\n",
    "H20_NEP_DF = pd.DataFrame(H20_NEP_data, columns=H20_NEP_data.columns.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c27a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening HDR3 detections catalog  ** double check this <-- statement ** and converting it into a pandas DF\n",
    "HDR_source_cat = fits.open('/home/jovyan/Hobby-Eberly-Telesco/hdr3/catalogs/source_catalog_3.0.1.fits', memmap = True)\n",
    "HDR3_data = HDR_source_cat[1].data\n",
    "HDR3_DF = pd.DataFrame(HDR3_data, columns=HDR3_data.columns.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87243526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns we will then take from the entire data set (it was huge so we needed to determine what we wanted to look at specifically).\n",
    "# As the name suggests, these are the ones that are useful to us!\n",
    "useful_hdr3_cols = ['source_id', 'detectid',  'selected_det', 'ra_mean', 'dec_mean', 'fwhm', 'shotid', 'field',  'ra', 'dec', 'wave', 'wave_err', 'flux', 'flux_err', 'sn', 'sn_err', 'chi2', 'chi2_err',\n",
    "'linewidth', 'linewidth_err', 'plya_classification', 'z_hetdex', 'z_hetdex_conf', 'combined_plae']\n",
    "\n",
    "# For now, the only useful columns for us in H20 NEP is RA and DEC.\n",
    "useful_h20nep_cols = ['RA_MODELING', 'DEC_MODELING', 'VALID_SOURCE_MODELING']\n",
    "\n",
    "# From the original DF, taking the useful columns\n",
    "reduced_hdr3_df = HDR3_DF.loc[:, useful_hdr3_cols]\n",
    "reduced_h20nep_df = H20_NEP_DF.loc[:, useful_h20nep_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888ba3f0",
   "metadata": {},
   "source": [
    "### Cleaning up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44649c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing data from before 2017 because it isn't good (not useful to us)\n",
    "# No need to do this for H20 NEP\n",
    "removed_bad_shots_hdr3_df = reduced_hdr3_df[reduced_hdr3_df.shotid.values >= 20180000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a97cd9",
   "metadata": {},
   "source": [
    "### Info for VALID_SOURCE_MODELING column\n",
    "\n",
    "for the H20 data we wont use any filters aside from the the VALID_SOURCE_MODELING column which just tells us that the model was able to converge and get fluxes from the source.\n",
    "\n",
    "No need! For H20 we wont use any filters aside from the the VALID_SOURCE_MODELING column which just tells us that the model was able to converge and get fluxes from the source.\n",
    "\n",
    "Nah the False valid source modeling means that the model used to measure the fluxes failed somehow so we cannot use that galaxy reliably\n",
    "\n",
    "We want the true ones since we know the model was able to find a galaxy and we can use that for our imaging counterpart identification (ie: to use these galaxy to check if there is a galaxy at our new extraction coordinate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc89194",
   "metadata": {},
   "source": [
    "### Filtering data. For HDR3 we use a signal to noise greater than 6.5 and for H20 NEP we check if the VALID_SOURCE_MODELING is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e5f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will give high confidence detections. Something we would want to do also. What is sn threshold that Valentina's code is having trouble with.\n",
    "# Reason why, we want high-confidence Lya. If we are very confident sn and another filter, then that's what we consider high-conf lya.\n",
    "# Once noise and high-confidence sample. We can start exanping on valentina's code and do our own stuff\n",
    "signal_to_noise_interval = removed_bad_shots_hdr3_df[removed_bad_shots_hdr3_df['sn'] > 6.5]\n",
    "\n",
    "# For now, no need to specify a field. But once trained, we want to run this for the NEP field!\n",
    "\n",
    "valid_source_check = reduced_h20nep_df[reduced_h20nep_df['VALID_SOURCE_MODELING'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2467aa59",
   "metadata": {},
   "source": [
    "### Picking a random source (from HDR3 only for now)  and applying an offset to that source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a489c592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picks a random source for us, the 1 means a single random source.\n",
    "# Might need to find a different way of getting a random source, just because I don't think\n",
    "# there's a way to control which source this gets, so it'll always be a different source!\n",
    "# Or just run this once\n",
    "random_source = signal_to_noise_interval.sample(n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94234a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_id</th>\n",
       "      <th>detectid</th>\n",
       "      <th>selected_det</th>\n",
       "      <th>ra_mean</th>\n",
       "      <th>dec_mean</th>\n",
       "      <th>fwhm</th>\n",
       "      <th>shotid</th>\n",
       "      <th>field</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>...</th>\n",
       "      <th>sn</th>\n",
       "      <th>sn_err</th>\n",
       "      <th>chi2</th>\n",
       "      <th>chi2_err</th>\n",
       "      <th>linewidth</th>\n",
       "      <th>linewidth_err</th>\n",
       "      <th>plya_classification</th>\n",
       "      <th>z_hetdex</th>\n",
       "      <th>z_hetdex_conf</th>\n",
       "      <th>combined_plae</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258490</th>\n",
       "      <td>3010000264888</td>\n",
       "      <td>3002741531</td>\n",
       "      <td>False</td>\n",
       "      <td>168.646988</td>\n",
       "      <td>51.249844</td>\n",
       "      <td>1.470759</td>\n",
       "      <td>20190307026</td>\n",
       "      <td>dex-spring</td>\n",
       "      <td>168.646713</td>\n",
       "      <td>51.249657</td>\n",
       "      <td>...</td>\n",
       "      <td>9.43</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>9.13</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.108464</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            source_id    detectid  selected_det     ra_mean   dec_mean  \\\n",
       "258490  3010000264888  3002741531         False  168.646988  51.249844   \n",
       "\n",
       "            fwhm       shotid       field          ra        dec  ...    sn  \\\n",
       "258490  1.470759  20190307026  dex-spring  168.646713  51.249657  ...  9.43   \n",
       "\n",
       "        sn_err  chi2  chi2_err  linewidth  linewidth_err  plya_classification  \\\n",
       "258490    0.78   2.3      0.22       9.13           2.44                 0.25   \n",
       "\n",
       "        z_hetdex  z_hetdex_conf  combined_plae  \n",
       "258490  0.108464            0.9          0.001  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99e57c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are using an offset to try to pick an area where there is no source.\n",
    "# This is a value we are experimenting with, going to go with 20 arcseconds for now\n",
    "offset = 20 * u.arcsec\n",
    "# need to convert to degrees so I can add to the ra and dec in catalog,\n",
    "# the ra and dec in catalog are in degrees\n",
    "offset = offset.to('deg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38f35710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying an offset, then we check if there is a source at the offset!\n",
    "delta_ra = random_source['ra'] + offset # I forgot how units work here, are these all in arcseconds?\n",
    "delta_dec = random_source['dec'] + offset # I forgot how units work here, are these all in arcseconds?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee4f7e4",
   "metadata": {},
   "source": [
    "## Should I make this check an or?\n",
    "Because this is saying, if the ra AND the dec are not in the catalog, then there is no source.\n",
    "\n",
    "But if only one isn't there then it's possible the source isn't in the catalog either right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f1c0a",
   "metadata": {},
   "source": [
    "Here I'm checking if the source in the HDR3 detections catalog? Ask about the catalog name because I think I'm getting mixed up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59f6572",
   "metadata": {},
   "source": [
    "When comparing the H20 NEP values to the running into"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8f0ae9",
   "metadata": {},
   "source": [
    "### Checking if the offset ra and dec are in either of the catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05629b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This truth_check df will check if the delta_ra and delta_dec are in the catalog. \n",
    "# If the size of this df is 0, then there is no source in this catalog with those specific ra and dec.\n",
    "truth_check_hdr3 = signal_to_noise_interval[(signal_to_noise_interval['ra'] == delta_ra.values[0])  \n",
    "                                            & (signal_to_noise_interval['dec'] == delta_dec.values[0])]\n",
    "\n",
    "# For this truth check I have to use np.isclose. The reason is, because the RA and DEC in the HDR3 catalog \n",
    "# values only go to 7 decimals and the h20 catalog numbers go to 14 decimals. So I can't check for equality\n",
    "# normality since I'll always get not equal. If I use close I can check if the numbers are close with a \n",
    "# certain chosen error.\n",
    "\n",
    "# If later on samples seem weirdly small, I need to come back and check this!!!!!!*********\n",
    "truth_check_h20 = valid_source_check[(np.isclose(valid_source_check['RA_MODELING'], delta_ra.values[0], 1e-9, 1e-10))\n",
    "                                   & (np.isclose(valid_source_check['DEC_MODELING'], delta_dec.values[0], 1e-9, 1e-10))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad73e825",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_check_hdr3.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2d9a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_check_h20.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd09c2",
   "metadata": {},
   "source": [
    "### Now we extract!\n",
    "\n",
    "Got a bit confused here with the slack messages. Also, wanted to make sure my previous code was right before continuing.\n",
    "\n",
    "\"You should have two RA and DEC skycoords for every coordinate in both catalogs and compare the new coordinate to these two\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a5b24f",
   "metadata": {},
   "source": [
    "## Ask about ICRS frame out of curiosity.\n",
    "Read documentation but still confused!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fcb23a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sky_coords = SkyCoord(delta_ra.values[0], delta_dec.values[0], frame = 'icrs', unit = 'deg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "124ddcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SkyCoord (ICRS): (ra, dec) in deg\n",
       "    (168.65226746, 51.25521088)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sky_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43c17855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO - 2022-10-14 02:44:21,748] Finding shots of interest\n",
      "[INFO - 2022-10-14 02:44:28,262] Number of shots of interest: 4\n",
      "[INFO - 2022-10-14 02:44:28,264] Extracting 4 sources\n",
      "[INFO - 2022-10-14 02:44:28,817] Working on shot: 20180115011\n",
      "[INFO - 2022-10-14 02:44:28,818] Working on shot: 20180212009\n",
      "[INFO - 2022-10-14 02:44:28,818] Working on shot: 20190307026\n",
      "[INFO - 2022-10-14 02:44:28,818] Working on shot: 20180208011\n",
      "[INFO - 2022-10-14 02:44:32,102] Extraction of sources completed in 0.06 minutes.\n",
      "[INFO - 2022-10-14 02:44:32,183] Retrieved 0 spectra.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><i>Table length=0</i>\n",
       "<table id=\"table140711319805504\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>ID</th><th>shotid</th><th>wavelength</th><th>spec</th><th>spec_err</th><th>apcor</th><th>flag</th><th>gal_flag</th><th>amp_flag</th><th>meteor_flag</th></tr></thead>\n",
       "<thead><tr><th></th><th></th><th>Angstrom</th><th>1e-17 erg / (Angstrom cm2 s)</th><th>1e-17 erg / (Angstrom cm2 s)</th><th></th><th></th><th></th><th></th><th></th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>int64</th><th>int64</th><th>int64</th><th>int64</th></tr></thead>\n",
       "</table></div>"
      ],
      "text/plain": [
       "<Table length=0>\n",
       "   ID    shotid wavelength ... gal_flag amp_flag meteor_flag\n",
       "                 Angstrom  ...                              \n",
       "float64 float64  float64   ...  int64    int64      int64   \n",
       "------- ------- ---------- ... -------- -------- -----------"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spectra(sky_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a3f4f4",
   "metadata": {},
   "source": [
    "## NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c20ad6",
   "metadata": {},
   "source": [
    "We want no source. This catalog has HETDEX detections one. \n",
    "\n",
    "    Want to make sure:\n",
    "        1.No hetdection detec\n",
    "        \n",
    "        2. No imaging counterpart. Do some cross-matching. Gives us a 0 and THEN we extract. Want to extract in basically empty space. Start with 100. \n",
    "        \n",
    "            Coordinates still. Trying to see if no match with the .fits file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330499d",
   "metadata": {},
   "source": [
    "Start with detection. One approach was fits file with coordinates. \n",
    "\n",
    "Or \n",
    "\n",
    "Use this but expand upon it. Find RA and DEC of each shot. And randomly extract.\n",
    "\n",
    "    delta ra and delta dec. Double check if is there a source there. \n",
    "    \n",
    "For noise sample, no need to run through valentina's code. Only focus on High-z after filtering through Valentina's code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a0dae8",
   "metadata": {},
   "source": [
    "Once we have noise sample.\n",
    "\n",
    "Run through valentina's code. Hopefully it detects them all as high-z. Cause neither low-z or star.\n",
    "\n",
    "Two skycoords. Check coordinates to see if HETDEX detection is there. Compare minimum separation. If the difference is smaller than 3 arcseconds. Then there is a source there, so do not extract there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
